# Neural-Networks-from-scratch
Mini-batch stochastic gradient descent implementation of Neural Network with one hidden layer.

The code also contains batch gradient descent implementation of backpropagation.

For mini-batch implementation run:
```
python exec_master.py
```

For batch implementation run:

```
python exec_normal.py
```

The mini-batch implementation of backpropagation step, runs 3.5 times faster than normal implementation.
